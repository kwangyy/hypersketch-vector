# HyperSketch Vector

A comprehensive system for generating, storing, and retrieving image descriptions using vector embeddings and AI models.

## ğŸ“ Project Structure

```
hypersketch-vector/
â”œâ”€â”€ src/                          # Source code modules
â”‚   â”œâ”€â”€ evaluation/               # Evaluation and testing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ evaluation.py         # Main evaluation logic and lambda sweep
â”‚   â”‚   â””â”€â”€ generation_evaluation.py  # Generate evaluation datasets
â”‚   â”œâ”€â”€ generation/               # Image description generation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ generation.py         # AI-powered description generation
â”‚   â”œâ”€â”€ retrieval/                # Vector operations and search
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ arithmetic.py         # Embedding preprocessing and math
â”‚   â”‚   â”œâ”€â”€ insertion.py          # Vector database insertion
â”‚   â”‚   â””â”€â”€ retrieval.py          # Search and retrieval logic
â”‚   â””â”€â”€ utils/                    # Shared utilities
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ data/                         # Data storage
â”‚   â”œâ”€â”€ descriptions/             # Generated descriptions and evaluations
â”‚   â”‚   â”œâ”€â”€ descriptions.json     # AI-generated image descriptions
â”‚   â”‚   â”œâ”€â”€ evaluation.json       # Evaluation datasets
â”‚   â”‚   â”œâ”€â”€ picture_id.json       # Image ID mappings
â”‚   â”‚   â””â”€â”€ test*.json            # Test data files
â”‚   â”œâ”€â”€ images/                   # Image files (formerly "Kwang Yang SREF Tests")
â”‚   â””â”€â”€ results/                  # Analysis and evaluation results
â”‚       â”œâ”€â”€ lambda_sweep_*.csv    # Lambda parameter analysis
â”‚       â””â”€â”€ *.csv                 # Other result files
â”œâ”€â”€ main.py                       # Main entry point and demo
â””â”€â”€ requirements.txt              # Python dependencies
```

## ğŸš€ Getting Started

### Installation

1. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

2. Set up environment variables:
   ```bash
   # Create .env file with:
   OPENAI_API_KEY=your_openai_api_key
   PINECONE_API_KEY=your_pinecone_api_key
   ```

### Basic Usage

Run the main demo:
```bash
python main.py
```

## ğŸ“‹ Module Usage

### 1. Generate Image Descriptions
```bash
python -m src.generation.generation
```
- Processes images in `data/images/`
- Generates AI descriptions using GPT-4
- Saves results to `data/descriptions/descriptions.json`

### 2. Insert Vectors into Database
```bash
python -m src.retrieval.insertion
```
- Embeds descriptions using OpenAI embeddings
- Uploads vectors to Pinecone database
- Handles deduplication automatically

### 3. Run Evaluations
```bash
python -m src.evaluation.evaluation
```
- Tests retrieval accuracy with different lambda values
- Generates comprehensive analysis reports
- Saves results to `data/results/`

### 4. Generate Evaluation Data
```bash
python -m src.evaluation.generation_evaluation
```
- Creates positive/negative/noisy paraphrases
- Builds evaluation datasets for testing
- Uses concurrent processing for efficiency

## ğŸ”§ Configuration

### Generation Settings
- **Model**: GPT-4o for image analysis
- **Batch Size**: 10 images per progress update
- **Retry Logic**: 3 attempts with exponential backoff

### Retrieval Settings  
- **Embedding Model**: OpenAI text-embedding-3-small (1536 dimensions)
- **Vector Database**: Pinecone with cosine similarity
- **Lambda Values**: Configurable positive/negative prompt weighting

### Evaluation Settings
- **Test Pairs**: 6 pairs per picture (positive+negative, noisy+negative)
- **Lambda Sweep**: Tests values from 0.0 to 1.0
- **Metrics**: Accuracy, rank distribution, pair type analysis

## ğŸ“Š Key Features

- **ğŸ¨ AI Description Generation**: Automated image analysis with detailed descriptors
- **ğŸ” Vector Search**: Efficient similarity search using embeddings
- **ğŸ“ˆ Comprehensive Evaluation**: Lambda parameter optimization and accuracy testing
- **âš¡ Concurrent Processing**: Multi-threaded operations for speed
- **ğŸ”„ Incremental Updates**: Smart deduplication and resumable operations
- **ğŸ“ Organized Structure**: Clean separation of concerns

## ğŸ§ª Evaluation Metrics

The system tracks several key metrics:
- **Overall Accuracy**: Percentage of correct retrievals
- **Rank Distribution**: Position of correct results in rankings  
- **Lambda Optimization**: Best positive/negative prompt weighting
- **Pair Type Analysis**: Performance by evaluation pair type

## ğŸ› ï¸ Development

### Adding New Features

1. **New Evaluation Methods**: Add to `src/evaluation/`
2. **Generation Improvements**: Modify `src/generation/generation.py`
3. **Retrieval Algorithms**: Update `src/retrieval/`
4. **Utility Functions**: Place in `src/utils/`

### Running Individual Components

Each module can be run independently:
```python
from src.retrieval import retrieve, embed
from src.generation import generate_descriptions
from src.evaluation import run_evaluation, main_lambda_sweep
```

## ğŸ“„ File Formats

- **descriptions.json**: `{filename: {id, path, description: [list]}}`
- **evaluation.json**: `{filename: [{paraphrased_prompt, paraphrase_type, picture_id}]}`
- **Results CSVs**: Pandas DataFrames with analysis results

## ğŸ”® Future Enhancements

- [ ] Web interface for interactive querying
- [ ] Additional embedding models support
- [ ] Real-time vector database updates
- [ ] Advanced evaluation metrics
- [ ] Automated hyperparameter tuning
